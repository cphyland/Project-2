{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1d57e9-2d35-427c-82a7-f6ac28c65294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# paths to access and save data\n",
    "shark_url = \"http://api.fish.wa.gov.au/webapi/v1/RawData\"\n",
    "ship_path = \"data/shipwrecks/ShipwrecksWAM_002.geojson\"\n",
    "\n",
    "def shark_data(api_url, start_date, end_date):\n",
    "    \"\"\"\n",
    "        Access the API at the specified URL, clean the data, filter the data, and return the JSON object as a pandas DataFrame\n",
    "\n",
    "            Args:\n",
    "                api_url (str): the URL to download the desired data from the API\n",
    "                start_date (str): return data beginning at this date YYYY-MM-DD\n",
    "                end_date (str): return data ending at this date YYYY-MM-DD\n",
    "    \"\"\"\n",
    "\n",
    "    # get a JSON object from the specified url, and convert it to a pandas dataframe\n",
    "    def get_sharks(api_url):\n",
    "    \n",
    "        response = requests.get(api_url).json()\n",
    "        sharks_df = pd.DataFrame(response)\n",
    "\n",
    "        return sharks_df\n",
    "\n",
    "    # clean the rawdata returned from the API to correct duplicate entries, and remove reports that are not sharks\n",
    "    def clean_sharks(sharks_df):\n",
    "        clean_sharks = sharks_df.copy()\n",
    "\n",
    "        # correct duplicate species entries present in the data\n",
    "        clean_sharks['SightingSpeciesValue'] = clean_sharks['SightingSpeciesValue'].replace({\n",
    "        'Whale Carcass':'whale carcass',\n",
    "        'whale carcass ':'whale carcass',\n",
    "        'whaler':'bronze whaler',\n",
    "        'shortfin mako':'mako', \n",
    "        'white ': 'white'})\n",
    "\n",
    "        # correct duplicate report owner entries present in the data\n",
    "        clean_sharks['OwnerValue'] = clean_sharks['OwnerValue'].replace({\n",
    "        'Fisheries advise': 'Fisheries Advise',\n",
    "        'SLS Lifesavers report ': 'SLS Lifesavers report',\n",
    "        'SLS Westpac Heli': 'SLS Westpac Heli report',\n",
    "        'Public Report': 'Public report'})\n",
    "\n",
    "        # drop entries that do not correspond to a confirmed shark sighting\n",
    "        drop_species = ['whale carcass',   # create a list of species values to filter out\n",
    "                        'detection event - possible',\n",
    "                        'other',\n",
    "                        'sonar object'] \n",
    "        species_filter = ~clean_sharks.SightingSpeciesValue.isin(drop_species) # use the list to create a filter\n",
    "        clean_sharks = clean_sharks[species_filter] # apply the filter to the dataframe\n",
    "\n",
    "        # limit the data to what is required by the leaflet plot\n",
    "        clean_sharks = clean_sharks[['InteractionValue','InteractionId','SightingSpeciesValue',\n",
    "                                    'SightingDateTime','OwnerValue','LocationX','LocationY']]\n",
    "\n",
    "        return clean_sharks\n",
    "\n",
    "    # limit the data to entries in a specified interval\n",
    "    def date_filter(data,start_date,end_date):\n",
    "        filtered_df = data.copy()\n",
    "        filtered_df = filtered_df.loc[\n",
    "        (clean_sharks[\"SightingDateTime\"] > start_date) & (clean_sharks[\"SightingDateTime\"] < end_date)]\n",
    "\n",
    "        return filtered_df\n",
    "\n",
    "    rawdata = get_sharks(api_url)\n",
    "    clean_data = clean_sharks(rawdata)\n",
    "    filtered_df = date_filter(clean_data,start_date,end_date)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def load_database(data_df, table_name, connection_string):\n",
    "    \"\"\" Create a table in a sqlite database from a pandas dataframe.\n",
    "     If the sqlite database does not exist, this will create one at the specified location.\n",
    "           \n",
    "            Args:\n",
    "                data_df (pandas.DataFrame): The pandas dataframe to be stored in the sqlite database\n",
    "                table_name (str): The name to use for the table\n",
    "                connection_string (str): The location of the sqlite database.\n",
    "                The database filename must end in .sqlite\n",
    "    \"\"\"\n",
    "    # create a connectiong to the database with sqlalchemy\n",
    "    engine = create_engine(f'sqlite://data/sharks/databasename.sqlite')\n",
    "\n",
    "    # load a table into the database with pandas\n",
    "    data_df.to_sql(table_name, con = engine)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f6182f-4e33-4cfc-b797-213a49fa8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_api_url = \"http://api.fish.wa.gov.au/webapi/v1/RawData\"\n",
    "shark_table_name = \"sharks\"\n",
    "shark_csv_path = \"../data/sharks/sharks_cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b560811f-755a-443f-8398-214a71084339",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a164efd500e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msharks_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshark_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshark_api_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"1/1/2020\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"7/1/2021\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-a68482838104>\u001b[0m in \u001b[0;36mshark_data\u001b[1;34m(api_url, start_date, end_date)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sharks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mclean_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_sharks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mfiltered_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-a68482838104>\u001b[0m in \u001b[0;36mget_sharks\u001b[1;34m(api_url)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_sharks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0msharks_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    898\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "sharks_df = shark_data(shark_api_url, \"1/1/2020\", \"7/1/2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3562f1-1047-4828-a821-c48b9dbaa797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
